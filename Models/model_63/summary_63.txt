Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
reshape (Reshape)            (None, 1, 200, 8)         0         
_________________________________________________________________
conv2d (Conv2D)              (None, 1, 200, 40)        4840      
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 1, 33, 40)         0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 1, 33, 24)         2904      
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 1, 16, 24)         0         
_________________________________________________________________
dropout (Dropout)            (None, 1, 16, 24)         0         
_________________________________________________________________
flatten (Flatten)            (None, 384)               0         
_________________________________________________________________
dense (Dense)                (None, 200)               77000     
_________________________________________________________________
batch_normalization (BatchNo (None, 200)               800       
_________________________________________________________________
activation (Activation)      (None, 200)               0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 200)               40200     
_________________________________________________________________
batch_normalization_1 (Batch (None, 200)               800       
_________________________________________________________________
activation_1 (Activation)    (None, 200)               0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 100)               20100     
_________________________________________________________________
batch_normalization_2 (Batch (None, 100)               400       
_________________________________________________________________
activation_2 (Activation)    (None, 100)               0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 50)                5050      
_________________________________________________________________
batch_normalization_3 (Batch (None, 50)                200       
_________________________________________________________________
activation_3 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_4 (Dense)              (None, 6)                 306       
=================================================================
Total params: 152,600
Trainable params: 151,500
Non-trainable params: 1,100
_________________________________________________________________
data_dir: C:\Users\hbkm9\Documents\Projects\CYB\Experiment1\CYB004\Data
window_size: 200
delay: 200
gap_windows: None
stride: 1
freq_factor: 20
file_names: ['004_Walk01.json', '004_Walk02.json', '004_Walk03.json', '004_Walk04.json', '004_Walk05.json', '004_Walk06.json', '004_Walk07.json', '004_Walk08.json', '004_Walk09.json', '004_Walk10.json', '004_Walk11.json', '004_Walk12.json', '004_Walk13.json', '004_Walk14.json', '004_Walk15.json', '004_Walk16.json', '004_Walk17.json', '004_Walk18.json', '004_Walk19.json']
channel_mask: [0, 1, 2, 3, 4, 5, 6, 7]
preproc: <function norm_emg at 0x0000027518A2DEE8>
batch_size: 64
input_shape: (200, 8)
n_outputs: 6
acts: ('relu', 'selu')
krnl: ((1, 15), (1, 3))
pad: same
dil: 10
mpool: ((1, 6), (1, 2))
depth_mul: (40, 24)
drp: 0.4
dense_drp: True
dense: (200, 200, 100, 50)
b_norm: True
